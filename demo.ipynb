{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bowcai/YOLOv3/blob/main/demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run the following block if in Google Colab."
      ],
      "metadata": {
        "id": "FWBt9sDxEWnE"
      },
      "id": "FWBt9sDxEWnE"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "c885a764-1968-4cc9-8b3d-c8447a579a61",
      "metadata": {
        "id": "c885a764-1968-4cc9-8b3d-c8447a579a61",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "625dd1f4-7f0f-44fb-8e60-a67b10d28a94"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'YOLOv3'...\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from subprocess import getoutput\n",
        "clone_output = getoutput(\"git clone https://github.com/bowcai/YOLOv3.git\")\n",
        "print(clone_output)\n",
        "os.chdir('YOLOv3')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "hFTeSQBKRq0-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9e6a17c-eaf1-4784-8569-ef872cb68804"
      },
      "id": "hFTeSQBKRq0-",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from yolov3.load_data import create_training_instances, BatchGenerator\n",
        "from yolov3.load_weight import load_keras_model, save_keras_model, load_pretrained_weight\n",
        "from yolov3.model import create_yolov3_model\n",
        "from yolov3.train import fit_model\n",
        "from yolov3.evaluate import evaluate"
      ],
      "metadata": {
        "id": "hYkQ7eOBFibx"
      },
      "id": "hYkQ7eOBFibx",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The path of training and validation set.\n",
        "proj_folder = '/content/drive/My Drive/Colab Notebooks/YOLOv3-proj/'\n",
        "train_annot_folder = proj_folder + 'kangaroo/annots/'\n",
        "train_img_folder = proj_folder + 'kangaroo/images/'\n",
        "train_cache_dir = proj_folder + 'kangaroo/cache.pkl'\n",
        "valid_annot_folder = None\n",
        "valid_img_folder = None\n",
        "valid_cache_dir = None\n",
        "\n",
        "# The labels of object classes.\n",
        "labels = ['kangaroo']\n",
        "\n",
        "# Batch size.\n",
        "batch_size = 16\n",
        "\n",
        "# Warmup batches.\n",
        "warmup_batches = 3\n",
        "\n",
        "# If the IoU of predicted bounding box with any ground truth box is higher than the threshold,\n",
        "# ignore the loss of the predicted box.\n",
        "ignore_thresh = 0.5\n",
        "\n",
        "grid_scales = [1, 1, 1]\n",
        "obj_scale = 5\n",
        "noobj_scale = 1\n",
        "xywh_scale = 1\n",
        "class_scale = 1\n",
        "\n",
        "# Minimum and maximum input size.\n",
        "min_input_size = 288\n",
        "max_input_size = 448\n",
        "\n",
        "# The pre-defined anchor sizes.\n",
        "anchors = [55, 69, 75, 234, 133, 240, 136, 129, 142, 363, 203, 290, 228, 184, 285, 359, 341, 260]\n",
        "\n",
        "# Ratio between network input's size and network output's size, 32 for YOLOv3.\n",
        "downsample = 32\n",
        "\n",
        "# The path of pre-trained YOLOv3 weights.\n",
        "pretrained_weight_path = proj_folder + 'weights/yolov3.weights'\n",
        "\n",
        "# The path of trained Keras model.\n",
        "keras_model_path = proj_folder + 'weights/kangaroo_model'\n"
      ],
      "metadata": {
        "id": "aAmCh0TkFoPV"
      },
      "id": "aAmCh0TkFoPV",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create training and validation set."
      ],
      "metadata": {
        "id": "Da45-2bTTo8M"
      },
      "id": "Da45-2bTTo8M"
    },
    {
      "cell_type": "code",
      "source": [
        "train_inst, valid_inst, labels, max_box_per_image = create_training_instances(\n",
        "    train_annot_folder,\n",
        "    train_img_folder,\n",
        "    train_cache_dir,\n",
        "    valid_annot_folder,\n",
        "    valid_img_folder,\n",
        "    valid_cache_dir,\n",
        "    labels\n",
        ")"
      ],
      "metadata": {
        "id": "GzCMOdVwKih1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5d9de47-fde0-43ae-a717-63476e10781b"
      },
      "id": "GzCMOdVwKih1",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valid_annot_folder not exists. Spliting the trainining set.\n",
            "Seen labels: \t{'kangaroo': 266}\n",
            "\n",
            "Given labels: \t['kangaroo']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create the mini-batch generators."
      ],
      "metadata": {
        "id": "mR6WSM-xT_2L"
      },
      "id": "mR6WSM-xT_2L"
    },
    {
      "cell_type": "code",
      "source": [
        "train_generator = BatchGenerator(\n",
        "    instances=train_inst,\n",
        "    anchors=anchors,\n",
        "    labels=labels,\n",
        "    downsample=downsample,\n",
        "    max_box_per_image=max_box_per_image,\n",
        "    batch_size=batch_size,\n",
        "    min_net_size=min_input_size,\n",
        "    max_net_size=max_input_size,\n",
        "    shuffle=True,\n",
        "    jitter=0.3,\n",
        "    norm=True\n",
        ")\n",
        "\n",
        "valid_generator = BatchGenerator(\n",
        "    instances=valid_inst,\n",
        "    anchors=anchors,\n",
        "    labels=labels,\n",
        "    downsample=downsample,\n",
        "    max_box_per_image=max_box_per_image,\n",
        "    batch_size=batch_size,\n",
        "    min_net_size=min_input_size,\n",
        "    max_net_size=max_input_size,\n",
        "    shuffle=True,\n",
        "    jitter=0.0,\n",
        "    norm=True\n",
        ")\n"
      ],
      "metadata": {
        "id": "h3pCK6bITrtP"
      },
      "id": "h3pCK6bITrtP",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_model, infer_model = create_yolov3_model(\n",
        "    nb_class=len(labels),\n",
        "    anchors=anchors,\n",
        "    max_box_per_image=max_box_per_image,\n",
        "    max_grid=[max_input_size, max_input_size],\n",
        "    batch_size=batch_size,\n",
        "    warmup_batches=warmup_batches,\n",
        "    ignore_thresh=ignore_thresh,\n",
        "    grid_scales=grid_scales,\n",
        "    obj_scale=obj_scale,\n",
        "    noobj_scale=noobj_scale,\n",
        "    xywh_scale=xywh_scale,\n",
        "    class_scale=class_scale,\n",
        ")"
      ],
      "metadata": {
        "id": "B_QUXB9xUakP"
      },
      "id": "B_QUXB9xUakP",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "load_pretrained_weight(infer_model, pretrained_weight_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_qKuHQOkad2",
        "outputId": "93a51e97-a239-49d1-b0b3-9de2ee157e68"
      },
      "id": "U_qKuHQOkad2",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading weights of convolution #0\n",
            "loading weights of convolution #1\n",
            "loading weights of convolution #2\n",
            "loading weights of convolution #3\n",
            "no convolution #4\n",
            "loading weights of convolution #5\n",
            "loading weights of convolution #6\n",
            "loading weights of convolution #7\n",
            "no convolution #8\n",
            "loading weights of convolution #9\n",
            "loading weights of convolution #10\n",
            "no convolution #11\n",
            "loading weights of convolution #12\n",
            "loading weights of convolution #13\n",
            "loading weights of convolution #14\n",
            "no convolution #15\n",
            "loading weights of convolution #16\n",
            "loading weights of convolution #17\n",
            "no convolution #18\n",
            "loading weights of convolution #19\n",
            "loading weights of convolution #20\n",
            "no convolution #21\n",
            "loading weights of convolution #22\n",
            "loading weights of convolution #23\n",
            "no convolution #24\n",
            "loading weights of convolution #25\n",
            "loading weights of convolution #26\n",
            "no convolution #27\n",
            "loading weights of convolution #28\n",
            "loading weights of convolution #29\n",
            "no convolution #30\n",
            "loading weights of convolution #31\n",
            "loading weights of convolution #32\n",
            "no convolution #33\n",
            "loading weights of convolution #34\n",
            "loading weights of convolution #35\n",
            "no convolution #36\n",
            "loading weights of convolution #37\n",
            "loading weights of convolution #38\n",
            "loading weights of convolution #39\n",
            "no convolution #40\n",
            "loading weights of convolution #41\n",
            "loading weights of convolution #42\n",
            "no convolution #43\n",
            "loading weights of convolution #44\n",
            "loading weights of convolution #45\n",
            "no convolution #46\n",
            "loading weights of convolution #47\n",
            "loading weights of convolution #48\n",
            "no convolution #49\n",
            "loading weights of convolution #50\n",
            "loading weights of convolution #51\n",
            "no convolution #52\n",
            "loading weights of convolution #53\n",
            "loading weights of convolution #54\n",
            "no convolution #55\n",
            "loading weights of convolution #56\n",
            "loading weights of convolution #57\n",
            "no convolution #58\n",
            "loading weights of convolution #59\n",
            "loading weights of convolution #60\n",
            "no convolution #61\n",
            "loading weights of convolution #62\n",
            "loading weights of convolution #63\n",
            "loading weights of convolution #64\n",
            "no convolution #65\n",
            "loading weights of convolution #66\n",
            "loading weights of convolution #67\n",
            "no convolution #68\n",
            "loading weights of convolution #69\n",
            "loading weights of convolution #70\n",
            "no convolution #71\n",
            "loading weights of convolution #72\n",
            "loading weights of convolution #73\n",
            "no convolution #74\n",
            "loading weights of convolution #75\n",
            "loading weights of convolution #76\n",
            "loading weights of convolution #77\n",
            "loading weights of convolution #78\n",
            "loading weights of convolution #79\n",
            "loading weights of convolution #80\n",
            "loading weights of convolution #81\n",
            "no convolution #82\n",
            "no convolution #83\n",
            "loading weights of convolution #84\n",
            "no convolution #85\n",
            "no convolution #86\n",
            "loading weights of convolution #87\n",
            "loading weights of convolution #88\n",
            "loading weights of convolution #89\n",
            "loading weights of convolution #90\n",
            "loading weights of convolution #91\n",
            "loading weights of convolution #92\n",
            "loading weights of convolution #93\n",
            "no convolution #94\n",
            "no convolution #95\n",
            "loading weights of convolution #96\n",
            "no convolution #97\n",
            "no convolution #98\n",
            "loading weights of convolution #99\n",
            "loading weights of convolution #100\n",
            "loading weights of convolution #101\n",
            "loading weights of convolution #102\n",
            "loading weights of convolution #103\n",
            "loading weights of convolution #104\n",
            "loading weights of convolution #105\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the model.\n",
        "fit_model(train_model, train_generator, valid_generator)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kH4jnTcuUlW3",
        "outputId": "6980eedd-800d-4a91-df0a-1dd963e3e8f0"
      },
      "id": "kH4jnTcuUlW3",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "resizing:  448 448\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['UnreadVariable', 'UnreadVariable', 'UnreadVariable'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['UnreadVariable', 'UnreadVariable', 'UnreadVariable'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "resizing:  352 352\n",
            "9/9 - 51s - loss: 799.6780 - yolo_layer_loss: 551.2206 - yolo_layer_1_loss: 82.0468 - yolo_layer_2_loss: 166.4106 - 51s/epoch - 6s/step\n",
            "Epoch 2/10\n",
            "resizing:  352 352\n",
            "resizing:  320 320\n",
            "9/9 - 6s - loss: 324.9985 - yolo_layer_loss: 104.9150 - yolo_layer_1_loss: 72.4178 - yolo_layer_2_loss: 147.6658 - 6s/epoch - 660ms/step\n",
            "Epoch 3/10\n",
            "resizing:  352 352\n",
            "resizing:  416 416\n",
            "9/9 - 14s - loss: 280.5604 - yolo_layer_loss: 71.7073 - yolo_layer_1_loss: 67.5106 - yolo_layer_2_loss: 141.3424 - 14s/epoch - 2s/step\n",
            "Epoch 4/10\n",
            "resizing:  352 352\n",
            "resizing:  320 320\n",
            "9/9 - 17s - loss: 283.2455 - yolo_layer_loss: 64.2132 - yolo_layer_1_loss: 68.4205 - yolo_layer_2_loss: 150.6118 - 17s/epoch - 2s/step\n",
            "Epoch 5/10\n",
            "resizing:  384 384\n",
            "9/9 - 15s - loss: 241.7750 - yolo_layer_loss: 46.3611 - yolo_layer_1_loss: 57.8472 - yolo_layer_2_loss: 137.5668 - 15s/epoch - 2s/step\n",
            "Epoch 6/10\n",
            "resizing:  384 384\n",
            "9/9 - 8s - loss: 223.0749 - yolo_layer_loss: 45.1561 - yolo_layer_1_loss: 48.6412 - yolo_layer_2_loss: 129.2776 - 8s/epoch - 836ms/step\n",
            "Epoch 7/10\n",
            "resizing:  320 320\n",
            "resizing:  448 448\n",
            "9/9 - 7s - loss: 191.2416 - yolo_layer_loss: 41.6989 - yolo_layer_1_loss: 37.2828 - yolo_layer_2_loss: 112.2599 - 7s/epoch - 805ms/step\n",
            "Epoch 8/10\n",
            "resizing:  416 416\n",
            "resizing:  384 384\n",
            "9/9 - 8s - loss: 193.0818 - yolo_layer_loss: 48.1736 - yolo_layer_1_loss: 31.2970 - yolo_layer_2_loss: 113.6112 - 8s/epoch - 940ms/step\n",
            "Epoch 9/10\n",
            "resizing:  416 416\n",
            "resizing:  384 384\n",
            "9/9 - 8s - loss: 152.2619 - yolo_layer_loss: 38.2651 - yolo_layer_1_loss: 22.1125 - yolo_layer_2_loss: 91.8843 - 8s/epoch - 897ms/step\n",
            "Epoch 10/10\n",
            "resizing:  448 448\n",
            "resizing:  384 384\n",
            "9/9 - 8s - loss: 117.2236 - yolo_layer_loss: 19.1026 - yolo_layer_1_loss: 17.7835 - yolo_layer_2_loss: 80.3374 - 8s/epoch - 918ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "save_keras_model(infer_model, keras_model_path)"
      ],
      "metadata": {
        "id": "xiU1_vlhVPia",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "522e962f-8c5a-4f1e-ab55-8cab4f13315a"
      },
      "id": "xiU1_vlhVPia",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 75). These functions will not be directly callable after loading.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "average_precisions = evaluate(infer_model, valid_generator)"
      ],
      "metadata": {
        "id": "Krli948IVXNr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "586e3517-621d-48b9-92f8-cda342be6bf8"
      },
      "id": "Krli948IVXNr",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-1b2346ce2e3f>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0maverage_precisions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minfer_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/YOLOv3/yolov3/evaluate.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(model, generator, iou_threshold, obj_thresh, nms_thresh, net_h, net_w, save_path)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;31m# make the boxes and the labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0mpred_boxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_yolo_boxes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnet_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnet_w\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_anchors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj_thresh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnms_thresh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mbox\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpred_boxes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/YOLOv3/yolov3/predict.py\u001b[0m in \u001b[0;36mget_yolo_boxes\u001b[0;34m(model, images, net_h, net_w, anchors, obj_thresh, nms_thresh)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;31m# correct the sizes of the bounding boxes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0mcorrect_yolo_boxes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_w\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnet_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnet_w\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;31m# suppress non-maximal boxes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/YOLOv3/yolov3/preprocess.py\u001b[0m in \u001b[0;36mcorrect_yolo_boxes\u001b[0;34m(boxes, image_h, image_w, net_h, net_w)\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0my_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_scale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnet_h\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mnew_h\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m2.\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnet_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_h\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnet_h\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m         \u001b[0mboxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxmin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxmin\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mx_offset\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mx_scale\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mimage_w\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m         \u001b[0mboxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxmax\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxmax\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mx_offset\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mx_scale\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mimage_w\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0mboxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mymin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mymin\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my_offset\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0my_scale\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mimage_h\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: cannot convert float NaN to integer"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for label, average_precision in average_precisions.items():\n",
        "    print(labels[label] + ': {:.4f}'.format(average_precision))\n",
        "print('mAP: {:.4f}'.format(sum(average_precisions.values()) / len(average_precisions)))"
      ],
      "metadata": {
        "id": "3ad_up7zVayp"
      },
      "id": "3ad_up7zVayp",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZtsT-mRJV08f"
      },
      "id": "ZtsT-mRJV08f",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}